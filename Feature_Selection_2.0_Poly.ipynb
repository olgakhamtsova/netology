{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reviews.csv', '.DS_Store', 'neighbourhoods.csv', 'listings.csv', 'calendar_summary.csv', 'reviews_summary.csv', '.ipynb_checkpoints', 'listings_summary.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "print(os.listdir('../FinalWork/berlin-airbnb-data'))\n",
    "\n",
    "df_reviews = pd.read_csv('../FinalWork/berlin-airbnb-data/reviews.csv')\n",
    "df_neighbourhoods = pd.read_csv('../FinalWork/berlin-airbnb-data/neighbourhoods.csv')\n",
    "df_listings = pd.read_csv('../FinalWork/berlin-airbnb-data/listings.csv')\n",
    "df_calendar_summary = pd.read_csv('../FinalWork/berlin-airbnb-data/calendar_summary.csv')\n",
    "df_reviews_summary = pd.read_csv('../FinalWork/berlin-airbnb-data/reviews_summary.csv')\n",
    "df_listings_summary = pd.read_csv('../FinalWork/berlin-airbnb-data/listings_summary.csv')\n",
    "\n",
    "df_listings_summary[\"host_since\"].fillna(0, inplace=True)\n",
    "\n",
    "df_listings_summary[\"host_since\"] = df_listings_summary[\"host_since\"].astype(\"str\")\n",
    "\n",
    "df_listings_summary[\"since\"] = df_listings_summary[\"host_since\"].apply(lambda x: x[:4])\n",
    "\n",
    "new = []\n",
    "new.append(\"since\")\n",
    "\n",
    "df_listings_summary.host_location.astype(\"str\")\n",
    "\n",
    "df_listings_summary[\"host_location\"].fillna(\"f\", inplace=True)\n",
    "\n",
    "df_listings_summary[\"is_hostinBerlin\"] = df_listings_summary[\"host_location\"].apply(lambda x: \"Berlin\" in x)\n",
    "\n",
    "new.append(\"is_hostinBerlin\")\n",
    "\n",
    "df_listings_summary[\"host_response_time\"].fillna(\"unknown\", inplace=True)\n",
    "\n",
    "def get_one_hot(df, cols):\n",
    "    \"\"\"\n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode \n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df\n",
    "\n",
    "cols_list = ['host_response_time']\n",
    "one_hot_df = get_one_hot(df_listings_summary[['host_response_time']], cols_list)\n",
    "\n",
    "one_hot_host_response_time = pd.get_dummies(df_listings_summary[['host_response_time']])\n",
    "\n",
    "df_listings_summary = pd.concat([df_listings_summary, one_hot_host_response_time], axis=1)\n",
    "\n",
    "\n",
    "for i in one_hot_host_response_time.columns:\n",
    "    new.append(i)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_listings_summary[\"host_response_rate\"].fillna(\"0%\", inplace=True)\n",
    "\n",
    "df_listings_summary[\"response_rate\"] = df_listings_summary[\"host_response_rate\"].apply(lambda x: x.replace(\"%\", \"\"))\n",
    "\n",
    "new.append(\"response_rate\")\n",
    "\n",
    "df_listings_summary[\"host_is_superhost\"].fillna(\"f\", inplace=True)\n",
    "\n",
    "new.append(\"host_is_superhost\")\n",
    "\n",
    "df_listings_summary[\"host_listings_count\"].fillna(0.0, inplace=True)\n",
    "\n",
    "new.append(\"host_listings_count\")\n",
    "\n",
    "df_listings_summary[\"host_has_profile_pic\"].fillna(\"f\", inplace=True)\n",
    "\n",
    "new.append(\"host_has_profile_pic\")\n",
    "\n",
    "df_listings_summary[\"host_identity_verified\"].fillna(\"f\", inplace=True)\n",
    "\n",
    "new.append(\"host_identity_verified\")\n",
    "\n",
    "one_hot_neighbourhood = pd.get_dummies(df_listings_summary[['neighbourhood_group_cleansed']])\n",
    "\n",
    "df_listings_summary = pd.concat([df_listings_summary, one_hot_neighbourhood], axis=1)\n",
    "\n",
    "for i in one_hot_neighbourhood.columns:\n",
    "    new.append(i)\n",
    "\n",
    "new.append(\"is_location_exact\")\n",
    "\n",
    "one_hot_room_type = pd.get_dummies(df_listings_summary[['room_type']])\n",
    "\n",
    "\n",
    "df_listings_summary = pd.concat([df_listings_summary, one_hot_room_type], axis=1)\n",
    "\n",
    "df_listings_summary[\"bathrooms\"].fillna(1.0, inplace=True)\n",
    "\n",
    "new.append(\"bathrooms\")\n",
    "\n",
    "new.append(\"accommodates\")\n",
    "\n",
    "df_listings_summary[\"bedrooms\"].fillna(1.0, inplace=True)\n",
    "\n",
    "new.append(\"bedrooms\")\n",
    "\n",
    "df_listings_summary[\"is_realbed\"] = df_listings_summary[\"bed_type\"].apply(lambda x: \"Real Bed\" in x)\n",
    "\n",
    "new.append(\"is_realbed\")\n",
    "\n",
    "df_listings_summary[\"security_deposit\"].fillna(\"$0.00\", inplace=True)\n",
    "df_listings_summary[\"cleaning_fee\"].fillna(\"$0.00\", inplace=True)\n",
    "df_listings_summary[\"extra_people\"].fillna(\"$0.00\", inplace=True)\n",
    "\n",
    "def remove_s(str_price):\n",
    "    if \"$\" in str_price:\n",
    "        str_price = str_price.replace(\"$\", \"\")\n",
    "    else:\n",
    "        pass\n",
    "    return str_price\n",
    "\n",
    "\n",
    "for s_column in [\"price\", \"security_deposit\", \"cleaning_fee\", \"extra_people\"]:\n",
    "    price_no_s = df_listings_summary[s_column].apply(remove_s)\n",
    "    df_listings_summary[s_column] = price_no_s\n",
    "\n",
    "def remove_c(str_price):\n",
    "    if \",\" in str_price:\n",
    "        str_price = str_price.replace(\",\", \"\")\n",
    "    else:\n",
    "        pass\n",
    "    return str_price\n",
    "\n",
    "\n",
    "for c_column in [\"price\", \"security_deposit\", \"cleaning_fee\", \"extra_people\"]:\n",
    "    price_no_c = df_listings_summary[c_column].apply(remove_c)\n",
    "    df_listings_summary[c_column] = price_no_c\n",
    "\n",
    "df_listings_summary[\"price\"] = df_listings_summary[\"price\"].astype(\"float\")\n",
    "\n",
    "for i in [\"security_deposit\", \"cleaning_fee\", \"extra_people\"]:\n",
    "    new.append(i)\n",
    "\n",
    "for i in [\"maximum_nights\", \"minimum_nights\"]:\n",
    "    new.append(i)\n",
    "\n",
    "df_listings_summary[\"cleaning_fee\"] = df_listings_summary[\"cleaning_fee\"].astype(\"float\")\n",
    "df_listings_summary[\"security_deposit\"] = df_listings_summary[\"security_deposit\"].astype(\"float\")\n",
    "df_listings_summary[\"extra_people\"] = df_listings_summary[\"extra_people\"].astype(\"float\")\n",
    "\n",
    "for i in [\"availability_30\", \"availability_60\", \"availability_90\", \"availability_365\"]:\n",
    "    new.append(i)\n",
    "\n",
    "new.append(\"instant_bookable\")\n",
    "\n",
    "df_listings_summary[\"is_cancellation_flexible\"] = df_listings_summary[\"cancellation_policy\"].apply(lambda x: \"flexible\" in x)\n",
    "\n",
    "new.append(\"is_cancellation_flexible\")\n",
    "\n",
    "new.append(\"calculated_host_listings_count\")\n",
    "\n",
    "df_listings_summary[\"reviews_per_month\"].fillna(\"0.00\", inplace=True)\n",
    "\n",
    "new.append(\"reviews_per_month\")\n",
    "\n",
    "new.append(\"id\")\n",
    "\n",
    "new.append(\"price\")\n",
    "\n",
    "df_selected = df_listings_summary[new].set_index('id')\n",
    "\n",
    "df_selected = df_selected[(df_selected.price \n",
    "                                 <= np.percentile(df_selected[\"price\"],\n",
    "                                99.5)) & (df_selected.price > 0)]\n",
    "\n",
    "df_selected[\"since\"] = df_selected[\"since\"].astype(\"int\")\n",
    "\n",
    "df_selected[\"response_rate\"] = df_selected[\"response_rate\"].astype(\"int\")\n",
    "\n",
    "df_selected[\"host_is_superhost\"] = df_selected[\"host_is_superhost\"]==\"t\"\n",
    "\n",
    "df_selected[\"host_has_profile_pic\"] = df_selected[\"host_has_profile_pic\"]==\"t\"\n",
    "\n",
    "df_selected[\"host_identity_verified\"] = df_selected[\"host_identity_verified\"]==\"t\"\n",
    "\n",
    "df_selected[\"is_location_exact\"] = df_selected[\"is_location_exact\"]==\"t\"\n",
    "\n",
    "df_selected[\"instant_bookable\"] = df_selected[\"instant_bookable\"]==\"t\"\n",
    "\n",
    "df_selected[\"reviews_per_month\"] = df_selected[\"reviews_per_month\"].astype(\"float\")\n",
    "\n",
    "for col in df_selected.select_dtypes(\"bool\").columns:\n",
    "    df_selected[col] = df_selected[col].astype(\"int\")\n",
    "\n",
    "df = df_selected\n",
    "\n",
    "features = []\n",
    "for col in df_selected.columns:\n",
    "    if col != \"price\":\n",
    "        features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = PolynomialFeatures(degree=3)\n",
    "PolyFeatures = trans.fit_transform(df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = PolyFeatures\n",
    "y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.00\n"
     ]
    }
   ],
   "source": [
    "# регрессия\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [5 0 0 ... 0 0 0]\n",
      " ...\n",
      " [2 0 0 ... 0 0 0]\n",
      " [2 0 0 ... 0 0 0]\n",
      " [7 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "         8.0       0.00      0.00      0.00       1.0\n",
      "         9.0       0.00      0.00      0.00       5.0\n",
      "        10.0       0.00      0.00      0.00       7.0\n",
      "        11.0       0.00      0.00      0.00       2.0\n",
      "        12.0       0.00      0.00      0.00       8.0\n",
      "        13.0       0.00      0.00      0.00      11.0\n",
      "        14.0       0.00      0.00      0.00      16.0\n",
      "        15.0       0.00      0.00      0.00      58.0\n",
      "        16.0       0.00      0.00      0.00      23.0\n",
      "        17.0       0.00      0.00      0.00      34.0\n",
      "        18.0       0.00      0.00      0.00      48.0\n",
      "        19.0       0.00      0.00      0.00      39.0\n",
      "        20.0       0.00      0.00      0.00     198.0\n",
      "        21.0       0.00      0.00      0.00      28.0\n",
      "        22.0       0.00      0.00      0.00      75.0\n",
      "        23.0       0.00      0.00      0.00      54.0\n",
      "        24.0       0.00      0.00      0.00      66.0\n",
      "        25.0       0.00      0.00      0.00     322.0\n",
      "        26.0       0.00      0.00      0.00      61.0\n",
      "        27.0       0.00      0.00      0.00      72.0\n",
      "        28.0       0.00      0.00      0.00      86.0\n",
      "        29.0       0.00      0.00      0.00     111.0\n",
      "        30.0       0.00      0.00      0.00     417.0\n",
      "        31.0       0.00      0.00      0.00      29.0\n",
      "        32.0       0.00      0.00      0.00      80.0\n",
      "        33.0       0.00      0.00      0.00      52.0\n",
      "        34.0       0.00      0.00      0.00      61.0\n",
      "        35.0       0.00      0.00      0.00     382.0\n",
      "        36.0       0.00      0.00      0.00      39.0\n",
      "        37.0       0.00      0.00      0.00      49.0\n",
      "        38.0       0.00      0.00      0.00      74.0\n",
      "        39.0       0.00      0.00      0.00     116.0\n",
      "        40.0       0.00      0.00      0.00     370.0\n",
      "        41.0       0.00      0.00      0.00      15.0\n",
      "        42.0       0.00      0.00      0.00      67.0\n",
      "        43.0       0.00      0.00      0.00      29.0\n",
      "        44.0       0.00      0.00      0.00      34.0\n",
      "        45.0       0.00      0.00      0.00     272.0\n",
      "        46.0       0.00      0.00      0.00      26.0\n",
      "        47.0       0.00      0.00      0.00      29.0\n",
      "        48.0       0.00      0.00      0.00      56.0\n",
      "        49.0       0.00      0.00      0.00     110.0\n",
      "        50.0       0.00      0.00      0.00     370.0\n",
      "        51.0       0.00      0.00      0.00      16.0\n",
      "        52.0       0.00      0.00      0.00      35.0\n",
      "        53.0       0.00      0.00      0.00      16.0\n",
      "        54.0       0.00      0.00      0.00      19.0\n",
      "        55.0       0.00      0.00      0.00     192.0\n",
      "        56.0       0.00      0.00      0.00      16.0\n",
      "        57.0       0.00      0.00      0.00      18.0\n",
      "        58.0       0.00      0.00      0.00      36.0\n",
      "        59.0       0.00      0.00      0.00      71.0\n",
      "        60.0       0.00      0.00      0.00     247.0\n",
      "        61.0       0.00      0.00      0.00       8.0\n",
      "        62.0       0.00      0.00      0.00      11.0\n",
      "        63.0       0.00      0.00      0.00      15.0\n",
      "        64.0       0.00      0.00      0.00      15.0\n",
      "        65.0       0.00      0.00      0.00     175.0\n",
      "        66.0       0.00      0.00      0.00      15.0\n",
      "        67.0       0.00      0.00      0.00      12.0\n",
      "        68.0       0.00      0.00      0.00      19.0\n",
      "        69.0       0.00      0.00      0.00      89.0\n",
      "        70.0       0.00      0.00      0.00     149.0\n",
      "        71.0       0.00      0.00      0.00       4.0\n",
      "        72.0       0.00      0.00      0.00       8.0\n",
      "        73.0       0.00      0.00      0.00       5.0\n",
      "        74.0       0.00      0.00      0.00       9.0\n",
      "        75.0       0.00      0.00      0.00     124.0\n",
      "        76.0       0.00      0.00      0.00       9.0\n",
      "        77.0       0.00      0.00      0.00       6.0\n",
      "        78.0       0.00      0.00      0.00      15.0\n",
      "        79.0       0.00      0.00      0.00      40.0\n",
      "        80.0       0.00      0.00      0.00     160.0\n",
      "        81.0       0.00      0.00      0.00       4.0\n",
      "        82.0       0.00      0.00      0.00       3.0\n",
      "        83.0       0.00      0.00      0.00       6.0\n",
      "        84.0       0.00      0.00      0.00      10.0\n",
      "        85.0       0.00      0.00      0.00      85.0\n",
      "        86.0       0.00      0.00      0.00       6.0\n",
      "        87.0       0.00      0.00      0.00       6.0\n",
      "        88.0       0.00      0.00      0.00      11.0\n",
      "        89.0       0.00      0.00      0.00      44.0\n",
      "        90.0       0.00      0.00      0.00     103.0\n",
      "        91.0       0.00      0.00      0.00       6.0\n",
      "        92.0       0.00      0.00      0.00       9.0\n",
      "        93.0       0.00      0.00      0.00       6.0\n",
      "        94.0       0.00      0.00      0.00       7.0\n",
      "        95.0       0.00      0.00      0.00      59.0\n",
      "        96.0       0.00      0.00      0.00       3.0\n",
      "        97.0       0.00      0.00      0.00       3.0\n",
      "        98.0       0.00      0.00      0.00      14.0\n",
      "        99.0       0.00      0.00      0.00      57.0\n",
      "       100.0       0.00      0.00      0.00     111.0\n",
      "       101.0       0.00      0.00      0.00       2.0\n",
      "       102.0       0.00      0.00      0.00       2.0\n",
      "       104.0       0.00      0.00      0.00       3.0\n",
      "       105.0       0.00      0.00      0.00      11.0\n",
      "       106.0       0.00      0.00      0.00       2.0\n",
      "       107.0       0.00      0.00      0.00       5.0\n",
      "       108.0       0.00      0.00      0.00       1.0\n",
      "       109.0       0.00      0.00      0.00      13.0\n",
      "       110.0       0.00      0.00      0.00      41.0\n",
      "       111.0       0.00      0.00      0.00       1.0\n",
      "       112.0       0.00      0.00      0.00       2.0\n",
      "       114.0       0.00      0.00      0.00       2.0\n",
      "       115.0       0.00      0.00      0.00      10.0\n",
      "       117.0       0.00      0.00      0.00       2.0\n",
      "       118.0       0.00      0.00      0.00       2.0\n",
      "       119.0       0.00      0.00      0.00      11.0\n",
      "       120.0       0.00      0.00      0.00      73.0\n",
      "       122.0       0.00      0.00      0.00       1.0\n",
      "       123.0       0.00      0.00      0.00       2.0\n",
      "       124.0       0.00      0.00      0.00       2.0\n",
      "       125.0       0.00      0.00      0.00      17.0\n",
      "       126.0       0.00      0.00      0.00       2.0\n",
      "       128.0       0.00      0.00      0.00       2.0\n",
      "       129.0       0.00      0.00      0.00      11.0\n",
      "       130.0       0.00      0.00      0.00      31.0\n",
      "       131.0       0.00      0.00      0.00       2.0\n",
      "       132.0       0.00      0.00      0.00       1.0\n",
      "       133.0       0.00      0.00      0.00       1.0\n",
      "       135.0       0.00      0.00      0.00      10.0\n",
      "       136.0       0.00      0.00      0.00       1.0\n",
      "       137.0       0.00      0.00      0.00       1.0\n",
      "       139.0       0.00      0.00      0.00       8.0\n",
      "       140.0       0.00      0.00      0.00      24.0\n",
      "       144.0       0.00      0.00      0.00       1.0\n",
      "       145.0       0.00      0.00      0.00      10.0\n",
      "       146.0       0.00      0.00      0.00       1.0\n",
      "       147.0       0.00      0.00      0.00       2.0\n",
      "       148.0       0.00      0.00      0.00       3.0\n",
      "       149.0       0.00      0.00      0.00      13.0\n",
      "       150.0       0.00      0.00      0.00      66.0\n",
      "       153.0       0.00      0.00      0.00       2.0\n",
      "       154.0       0.00      0.00      0.00       1.0\n",
      "       155.0       0.00      0.00      0.00       7.0\n",
      "       156.0       0.00      0.00      0.00       1.0\n",
      "       158.0       0.00      0.00      0.00       1.0\n",
      "       159.0       0.00      0.00      0.00       1.0\n",
      "       160.0       0.00      0.00      0.00      13.0\n",
      "       165.0       0.00      0.00      0.00       4.0\n",
      "       169.0       0.00      0.00      0.00       3.0\n",
      "       170.0       0.00      0.00      0.00      10.0\n",
      "       172.0       0.00      0.00      0.00       2.0\n",
      "       175.0       0.00      0.00      0.00       3.0\n",
      "       179.0       0.00      0.00      0.00       3.0\n",
      "       180.0       0.00      0.00      0.00      16.0\n",
      "       182.0       0.00      0.00      0.00       1.0\n",
      "       185.0       0.00      0.00      0.00       4.0\n",
      "       187.0       0.00      0.00      0.00       1.0\n",
      "       188.0       0.00      0.00      0.00       1.0\n",
      "       189.0       0.00      0.00      0.00       6.0\n",
      "       190.0       0.00      0.00      0.00       5.0\n",
      "       191.0       0.00      0.00      0.00       1.0\n",
      "       195.0       0.00      0.00      0.00       5.0\n",
      "       197.0       0.00      0.00      0.00       2.0\n",
      "       198.0       0.00      0.00      0.00       2.0\n",
      "       199.0       0.00      0.00      0.00       8.0\n",
      "       200.0       0.00      0.00      0.00      27.0\n",
      "       209.0       0.00      0.00      0.00       1.0\n",
      "       210.0       0.00      0.00      0.00       5.0\n",
      "       214.0       0.00      0.00      0.00       3.0\n",
      "       215.0       0.00      0.00      0.00       1.0\n",
      "       219.0       0.00      0.00      0.00       3.0\n",
      "       220.0       0.00      0.00      0.00       7.0\n",
      "       222.0       0.00      0.00      0.00       2.0\n",
      "       225.0       0.00      0.00      0.00       1.0\n",
      "       227.0       0.00      0.00      0.00       1.0\n",
      "       228.0       0.00      0.00      0.00       1.0\n",
      "       229.0       0.00      0.00      0.00       3.0\n",
      "       230.0       0.00      0.00      0.00       2.0\n",
      "       234.0       0.00      0.00      0.00       1.0\n",
      "       235.0       0.00      0.00      0.00       1.0\n",
      "       240.0       0.00      0.00      0.00       4.0\n",
      "       241.0       0.00      0.00      0.00       2.0\n",
      "       244.0       0.00      0.00      0.00       1.0\n",
      "       245.0       0.00      0.00      0.00       2.0\n",
      "       249.0       0.00      0.00      0.00       2.0\n",
      "       250.0       0.00      0.00      0.00      14.0\n",
      "       252.0       0.00      0.00      0.00       1.0\n",
      "       255.0       0.00      0.00      0.00       1.0\n",
      "       258.0       0.00      0.00      0.00       1.0\n",
      "       259.0       0.00      0.00      0.00       1.0\n",
      "       260.0       0.00      0.00      0.00       1.0\n",
      "       265.0       0.00      0.00      0.00       1.0\n",
      "       269.0       0.00      0.00      0.00       1.0\n",
      "       280.0       0.00      0.00      0.00       5.0\n",
      "       285.0       0.00      0.00      0.00       1.0\n",
      "       290.0       0.00      0.00      0.00       1.0\n",
      "       299.0       0.00      0.00      0.00       1.0\n",
      "       300.0       0.00      0.00      0.00       7.0\n",
      "       304.0       0.00      0.00      0.00       1.0\n",
      "       349.0       0.00      0.00      0.00       1.0\n",
      "       350.0       0.00      0.00      0.00       6.0\n",
      "       359.0       0.00      0.00      0.00       1.0\n",
      "       390.0       0.00      0.00      0.00       2.0\n",
      "       399.0       0.00      0.00      0.00       2.0\n",
      "       400.0       0.00      0.00      0.00       7.0\n",
      "\n",
      "    accuracy                           0.00    6733.0\n",
      "   macro avg       0.00      0.00      0.00    6733.0\n",
      "weighted avg       0.00      0.00      0.00    6733.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 71.3844\n",
      "MAE: 56.953215505718106\n"
     ]
    }
   ],
   "source": [
    "RMSE_reg = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae_reg = metrics.mean_absolute_error(y_test, y_pred)\n",
    "print(f\"RMSE: {round(RMSE_reg, 4)}\")\n",
    "print(\"MAE:\",mae_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR\n",
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = regressor.predict(X_test)\n",
    "RMSE_svr = np.sqrt(mean_squared_error(y_test, y_pred2))\n",
    "mae_svr = metrics.mean_absolute_error(y_test, y_pred2)\n",
    "print(f\"RMSE: {round(RMSE_svr, 4)}\")\n",
    "print(\"MAE:\",mae_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Создаём модель леса из сотни деревьев\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Действующая классификация\n",
    "rf_predictions = model.predict(X_test)\n",
    "# Вероятности для каждого класса\n",
    "rf_probs = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "mae = metrics.mean_absolute_error(y_test, rf_predictions)\n",
    "print(f\"RMSE: {round(RMSE, 4)}\")\n",
    "print(\"MAE:\",mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBRegressor()\n",
    "parameters = {'n_estimators': [120, 100, 140], 'max_depth':[3,5,7,9]}\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=parameters, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:12:02] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "R^2 score:  0.5344\n",
      "RMSE:  29.3639\n",
      "MAE: 17.893672883625673\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBRegressor(n_estimators=140, max_depth=5)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_test_pred = xgb_clf.predict(X_test)\n",
    "print(\"R^2 score: {0: .4f}\".format(r2_score(y_test, y_test_pred)))\n",
    "print(\"RMSE: {0: .4f}\".format(np.sqrt(mean_squared_error(y_test, y_test_pred))))\n",
    "mae = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "print(\"MAE:\",mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Feature Selection Data</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Polynominal Data</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Full Dataset</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Polynominal Full Dataset</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>MAE</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>MAE</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>MAE</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>MAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>35.1951</td>\n",
       "      <td>20.4705</td>\n",
       "      <td>79.0</td>\n",
       "      <td>46.5611</td>\n",
       "      <td>36.954</td>\n",
       "      <td>21.7375</td>\n",
       "      <td>71.3844</td>\n",
       "      <td>56.9532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVR</td>\n",
       "      <td>32.5832</td>\n",
       "      <td>18.3961</td>\n",
       "      <td>35.4302</td>\n",
       "      <td>21.0012</td>\n",
       "      <td>35.1407</td>\n",
       "      <td>20.2288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>35.5791</td>\n",
       "      <td>19.7946</td>\n",
       "      <td>35.8057</td>\n",
       "      <td>19.6206</td>\n",
       "      <td>34.5738</td>\n",
       "      <td>20.4075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>26.5518</td>\n",
       "      <td>15.2361</td>\n",
       "      <td>27.0310</td>\n",
       "      <td>15.7016</td>\n",
       "      <td>28.8621</td>\n",
       "      <td>17.8052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0 Feature Selection Data Unnamed: 2 Polynominal Data  \\\n",
       "0                 NaN                   RMSE        MAE             RMSE   \n",
       "1  LogisticRegression                35.1951    20.4705             79.0   \n",
       "2                 SVR                32.5832    18.3961          35.4302   \n",
       "3        RandomForest                35.5791    19.7946          35.8057   \n",
       "4             xgboost                26.5518    15.2361          27.0310   \n",
       "\n",
       "  Unnamed: 4 Full Dataset Unnamed: 6 Polynominal Full Dataset Unnamed: 8  \n",
       "0        MAE         RMSE        MAE                     RMSE        MAE  \n",
       "1    46.5611       36.954    21.7375                  71.3844    56.9532  \n",
       "2    21.0012      35.1407    20.2288                      NaN        NaN  \n",
       "3    19.6206      34.5738    20.4075                      NaN        NaN  \n",
       "4    15.7016      28.8621    17.8052                      NaN        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.read_excel('./metrics.xlsx')\n",
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
